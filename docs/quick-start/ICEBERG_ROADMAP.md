# Icebergæ¨¡å¼åŠŸèƒ½éœ€æ±‚åˆ—è¡¨å’Œå®ç°æ–¹æ¡ˆ

## ğŸ“‹ ç›®å½•

1. [éœ€æ±‚ä¼˜å…ˆçº§åˆ†ç±»](#éœ€æ±‚ä¼˜å…ˆçº§åˆ†ç±»)
2. [é«˜ä¼˜å…ˆçº§éœ€æ±‚](#é«˜ä¼˜å…ˆçº§éœ€æ±‚)
3. [ä¸­ä¼˜å…ˆçº§éœ€æ±‚](#ä¸­ä¼˜å…ˆçº§éœ€æ±‚)
4. [ä½ä¼˜å…ˆçº§éœ€æ±‚](#ä½ä¼˜å…ˆçº§éœ€æ±‚)
5. [OSSæ”¯æŒæ–¹æ¡ˆ](#ossæ”¯æŒæ–¹æ¡ˆ)

---

## ğŸ¯ éœ€æ±‚ä¼˜å…ˆçº§åˆ†ç±»

### é«˜ä¼˜å…ˆçº§ï¼ˆP0 - ç”Ÿäº§å¿…éœ€ï¼‰
- Schema Evolutionï¼ˆæ¨¡å¼æ¼”è¿›ï¼‰
- å»é‡æœºåˆ¶ï¼ˆDuplicate Handlingï¼‰
- Kafkaäº‹åŠ¡æ”¯æŒ
- ç¼“å­˜æ”¯æŒ

### ä¸­ä¼˜å…ˆçº§ï¼ˆP1 - é‡è¦åŠŸèƒ½ï¼‰
- è¡¨å‹ç¼©å’Œå¿«ç…§ç®¡ç†
- ParquetåŠ å¯†
- ç§»é™¤è¯»å–æ—¶å¯¹Catalogçš„ä¾èµ–
- GCSå’ŒAzure Blob Storageæ”¯æŒï¼ˆIcebergæ¨¡å¼ï¼‰

### ä½ä¼˜å…ˆçº§ï¼ˆP2 - å¢å¼ºåŠŸèƒ½ï¼‰
- å…¶ä»–å­˜å‚¨æ ¼å¼ï¼ˆAvroã€ORCï¼‰
- å…¶ä»–è®°å½•æ ¼å¼ï¼ˆJSONã€Protobufï¼‰
- å…¶ä»–è¡¨æ ¼å¼ï¼ˆDelta Lakeï¼‰
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- æ¨¡å—åŒ–é‡æ„

---

## ğŸ”´ é«˜ä¼˜å…ˆçº§éœ€æ±‚ï¼ˆP0ï¼‰

### 1. Schema Evolutionï¼ˆæ¨¡å¼æ¼”è¿›ï¼‰

#### éœ€æ±‚æè¿°
å½“å‰å®ç°ä¸­ï¼Œè¡¨çš„Schemaç”±ç¬¬ä¸€ä¸ªé‡åˆ°çš„è®°å½•å†³å®šï¼Œä¹‹åæ— æ³•æ›´æ”¹ã€‚è¿™é™åˆ¶äº†ç”Ÿäº§ç¯å¢ƒçš„ä½¿ç”¨ï¼Œå› ä¸ºå®é™…ä¸šåŠ¡ä¸­Schemaä¼šä¸æ–­æ¼”è¿›ã€‚

#### å½“å‰é™åˆ¶
- Schemaåœ¨è¡¨åˆ›å»ºæ—¶å›ºå®š
- ä¸æ”¯æŒæ·»åŠ /åˆ é™¤å­—æ®µ
- ä¸æ”¯æŒå­—æ®µç±»å‹å˜æ›´
- ä¸æ”¯æŒå­—æ®µé‡å‘½å

#### å®ç°æ–¹æ¡ˆ

##### 1.1 Schemaå…¼å®¹æ€§æ£€æŸ¥

**æ–‡ä»¶ä½ç½®ï¼š** `core/src/main/java/io/aiven/kafka/tieredstorage/iceberg/data/SchemaUpdate.java`

```java
public class SchemaEvolutionManager {
    
    /**
     * æ£€æŸ¥æ–°Schemaæ˜¯å¦ä¸ç°æœ‰Schemaå…¼å®¹
     * 
     * å…¼å®¹æ€§è§„åˆ™ï¼š
     * 1. æ·»åŠ å­—æ®µï¼šå…¼å®¹ï¼ˆæ–°å­—æ®µä¸ºå¯é€‰ï¼‰
     * 2. åˆ é™¤å­—æ®µï¼šä¸å…¼å®¹ï¼ˆé™¤éå­—æ®µå·²æ ‡è®°ä¸ºdeprecatedï¼‰
     * 3. ç±»å‹å˜æ›´ï¼šæ£€æŸ¥æ˜¯å¦å¯å®‰å…¨è½¬æ¢
     * 4. å­—æ®µé‡å‘½åï¼šéœ€è¦æ˜¾å¼æ˜ å°„
     */
    public SchemaCompatibilityResult checkCompatibility(
        Schema existingSchema,
        Schema newSchema,
        SchemaRegistryCompatibilityLevel compatibilityLevel) {
        
        // 1. æ£€æŸ¥Schema Registryçš„å…¼å®¹æ€§çº§åˆ«
        // 2. æ¯”è¾ƒå­—æ®µå·®å¼‚
        // 3. æ£€æŸ¥ç±»å‹è½¬æ¢å®‰å…¨æ€§
        // 4. è¿”å›å…¼å®¹æ€§ç»“æœ
    }
    
    /**
     * æ›´æ–°Icebergè¡¨Schema
     */
    public void evolveTableSchema(Table table, Schema newSchema) {
        // 1. æ£€æŸ¥å…¼å®¹æ€§
        // 2. æ›´æ–°è¡¨Schema
        // 3. è®°å½•Schemaå˜æ›´å†å²
    }
}
```

##### 1.2 Schemaå˜æ›´å¤„ç†æµç¨‹

```java
// åœ¨IcebergWriterä¸­å¤„ç†Schemaå˜æ›´
public class IcebergWriter {
    
    private Schema currentTableSchema;
    private Schema currentRecordSchema;
    
    public void writeRecord(GenericRecord record) {
        Schema recordSchema = record.getSchema();
        
        // æ£€æŸ¥Schemaæ˜¯å¦å˜æ›´
        if (!recordSchema.equals(currentRecordSchema)) {
            handleSchemaChange(recordSchema);
        }
        
        // è½¬æ¢è®°å½•ä»¥åŒ¹é…è¡¨Schema
        GenericRecord adaptedRecord = adaptRecord(record, currentTableSchema);
        writer.write(adaptedRecord);
    }
    
    private void handleSchemaChange(Schema newSchema) {
        // 1. æ£€æŸ¥å…¼å®¹æ€§
        SchemaCompatibilityResult result = 
            schemaEvolutionManager.checkCompatibility(
                currentTableSchema, newSchema, compatibilityLevel);
        
        if (result.isCompatible()) {
            // 2. æ›´æ–°è¡¨Schema
            schemaEvolutionManager.evolveTableSchema(table, newSchema);
            currentTableSchema = newSchema;
        } else {
            // 3. å¤„ç†ä¸å…¼å®¹æƒ…å†µ
            handleIncompatibleSchema(newSchema, result);
        }
    }
    
    private GenericRecord adaptRecord(GenericRecord record, Schema targetSchema) {
        // 1. å¤„ç†æ–°å¢å­—æ®µï¼ˆè®¾ä¸ºnullæˆ–é»˜è®¤å€¼ï¼‰
        // 2. å¤„ç†åˆ é™¤å­—æ®µï¼ˆå¿½ç•¥ï¼‰
        // 3. å¤„ç†ç±»å‹è½¬æ¢
        // 4. å¤„ç†å­—æ®µé‡å‘½å
    }
}
```

##### 1.3 é…ç½®é¡¹

```properties
# Schemaæ¼”è¿›é…ç½®
rsm.config.iceberg.schema.evolution.enabled=true
rsm.config.iceberg.schema.evolution.compatibility.level=BACKWARD
# å¯é€‰å€¼: BACKWARD, FORWARD, FULL, NONE

# Schemaå˜æ›´ç­–ç•¥
rsm.config.iceberg.schema.evolution.strategy=AUTO
# å¯é€‰å€¼: AUTO, MANUAL, STRICT
```

##### 1.4 å®ç°æ­¥éª¤

1. **Phase 1: Schemaå…¼å®¹æ€§æ£€æŸ¥** (2å‘¨)
   - å®ç°Schemaæ¯”è¾ƒé€»è¾‘
   - å®ç°å…¼å®¹æ€§è§„åˆ™
   - å•å…ƒæµ‹è¯•

2. **Phase 2: Schemaæ›´æ–°** (2å‘¨)
   - å®ç°Icebergè¡¨Schemaæ›´æ–°
   - å®ç°è®°å½•é€‚é…é€»è¾‘
   - é›†æˆæµ‹è¯•

3. **Phase 3: Schema Registryé›†æˆ** (1å‘¨)
   - ä¸Schema Registryé›†æˆ
   - æ”¯æŒå…¼å®¹æ€§çº§åˆ«æ£€æŸ¥
   - ç«¯åˆ°ç«¯æµ‹è¯•

**é¢„è®¡å·¥ä½œé‡ï¼š** 5å‘¨

---

### 2. å»é‡æœºåˆ¶ï¼ˆDuplicate Handlingï¼‰

#### éœ€æ±‚æè¿°
å½“å‰å®ç°ä¸­ï¼Œç”±äºLeaderåˆ‡æ¢æˆ–é‡è¯•ï¼ŒåŒä¸€ä¸ªoffsetå¯èƒ½è¢«ä¸Šä¼ å¤šæ¬¡ï¼Œå¯¼è‡´Icebergè¡¨ä¸­å‡ºç°é‡å¤è®°å½•ã€‚éœ€è¦å®ç°å»é‡æœºåˆ¶ã€‚

#### å½“å‰é—®é¢˜
- é‡å¤è®°å½•å¯¹Icebergè¯»è€…å¯è§
- å½±å“æ•°æ®è´¨é‡
- å¢åŠ å­˜å‚¨æˆæœ¬

#### å®ç°æ–¹æ¡ˆ

##### 2.1 åŸºäºKafkaå…ƒæ•°æ®çš„å»é‡

```java
public class DeduplicationManager {
    
    /**
     * æ£€æŸ¥è®°å½•æ˜¯å¦å·²å­˜åœ¨
     * ä½¿ç”¨ (topic, partition, offset) ä½œä¸ºå”¯ä¸€é”®
     */
    public boolean isDuplicate(
        String topic,
        int partition,
        long offset,
        Table table) {
        
        // ä½¿ç”¨Icebergçš„è¿‡æ»¤åŠŸèƒ½æŸ¥è¯¢
        Expression filter = Expressions.and(
            Expressions.equal("kafka.partition", partition),
            Expressions.equal("kafka.offset", offset)
        );
        
        try (CloseableIterable<FileScanTask> tasks = 
            table.newScan().filter(filter).planFiles()) {
            
            return tasks.iterator().hasNext();
        }
    }
    
    /**
     * æ‰¹é‡å»é‡æ£€æŸ¥
     */
    public Set<Long> findDuplicates(
        String topic,
        int partition,
        List<Long> offsets,
        Table table) {
        
        // ä½¿ç”¨INæŸ¥è¯¢ä¼˜åŒ–æ€§èƒ½
        Expression filter = Expressions.and(
            Expressions.equal("kafka.partition", partition),
            Expressions.in("kafka.offset", offsets)
        );
        
        Set<Long> existingOffsets = new HashSet<>();
        try (CloseableIterable<Row> rows = 
            table.newScan().filter(filter).planRows()) {
            
            for (Row row : rows) {
                existingOffsets.add(row.getLong("kafka.offset"));
            }
        }
        
        return existingOffsets;
    }
}
```

##### 2.2 å†™å…¥æ—¶å»é‡

```java
// åœ¨IcebergWriterä¸­é›†æˆå»é‡
public class IcebergWriter {
    
    private final DeduplicationManager deduplicationManager;
    
    public void writeBatch(List<GenericRecord> records) {
        // 1. æå–offsets
        List<Long> offsets = extractOffsets(records);
        
        // 2. æ‰¹é‡æ£€æŸ¥é‡å¤
        Set<Long> duplicates = deduplicationManager.findDuplicates(
            topicName, partition, offsets, table);
        
        // 3. è¿‡æ»¤é‡å¤è®°å½•
        List<GenericRecord> uniqueRecords = records.stream()
            .filter(record -> {
                long offset = getOffset(record);
                return !duplicates.contains(offset);
            })
            .collect(Collectors.toList());
        
        // 4. å†™å…¥å”¯ä¸€è®°å½•
        if (!uniqueRecords.isEmpty()) {
            writer.writeBatch(uniqueRecords);
        }
    }
}
```

##### 2.3 æ€§èƒ½ä¼˜åŒ–

**ä½¿ç”¨Bloom Filterï¼š**
```java
public class BloomFilterDeduplication {
    
    private final BloomFilter<Long> offsetBloomFilter;
    
    public boolean mightContain(long offset) {
        return offsetBloomFilter.mightContain(offset);
    }
    
    // å®šæœŸä»Icebergè¡¨é‡å»ºBloom Filter
    public void rebuildBloomFilter(Table table) {
        // æ‰«æè¡¨ï¼Œæå–æ‰€æœ‰offsets
        // é‡å»ºBloom Filter
    }
}
```

##### 2.4 é…ç½®é¡¹

```properties
# å»é‡é…ç½®
rsm.config.iceberg.deduplication.enabled=true
rsm.config.iceberg.deduplication.strategy=KAFKA_METADATA
# å¯é€‰å€¼: KAFKA_METADATA, BLOOM_FILTER, HYBRID

# Bloom Filteré…ç½®
rsm.config.iceberg.deduplication.bloom.filter.enabled=true
rsm.config.iceberg.deduplication.bloom.filter.rebuild.interval.ms=3600000
```

##### 2.5 å®ç°æ­¥éª¤

1. **Phase 1: åŸºç¡€å»é‡** (2å‘¨)
   - å®ç°åŸºäºoffsetçš„å»é‡æ£€æŸ¥
   - é›†æˆåˆ°å†™å…¥æµç¨‹
   - å•å…ƒæµ‹è¯•

2. **Phase 2: æ€§èƒ½ä¼˜åŒ–** (2å‘¨)
   - å®ç°Bloom Filter
   - æ‰¹é‡å»é‡æ£€æŸ¥
   - æ€§èƒ½æµ‹è¯•

3. **Phase 3: ç›‘æ§å’ŒæŒ‡æ ‡** (1å‘¨)
   - æ·»åŠ å»é‡æŒ‡æ ‡
   - ç›‘æ§é‡å¤ç‡
   - æ–‡æ¡£æ›´æ–°

**é¢„è®¡å·¥ä½œé‡ï¼š** 5å‘¨

---

### 3. Kafkaäº‹åŠ¡æ”¯æŒ

#### éœ€æ±‚æè¿°
å½“å‰å®ç°ä¸æ”¯æŒKafkaäº‹åŠ¡ï¼Œå¦‚æœæ®µä¸­åŒ…å«äº‹åŠ¡æ§åˆ¶æ‰¹æ¬¡ï¼Œæ•´ä¸ªæ®µæ— æ³•ä¸Šä¼ ã€‚

#### å½“å‰é™åˆ¶
- ä¸æ”¯æŒäº‹åŠ¡æ§åˆ¶æ‰¹æ¬¡
- ä¸æ”¯æŒäº‹åŠ¡æ€§æ•°æ®
- ä¸æ”¯æŒäº‹åŠ¡æäº¤/ä¸­æ­¢è¯­ä¹‰

#### å®ç°æ–¹æ¡ˆ

##### 3.1 äº‹åŠ¡æ‰¹æ¬¡è¯†åˆ«

```java
public class TransactionBatchHandler {
    
    /**
     * æ£€æŸ¥æ‰¹æ¬¡æ˜¯å¦ä¸ºäº‹åŠ¡æ§åˆ¶æ‰¹æ¬¡
     */
    public boolean isTransactionControlBatch(RecordBatch batch) {
        return batch.isControlBatch() && 
               batch.producerId() != RecordBatch.NO_PRODUCER_ID;
    }
    
    /**
     * æå–äº‹åŠ¡ä¿¡æ¯
     */
    public TransactionInfo extractTransactionInfo(RecordBatch batch) {
        return TransactionInfo.builder()
            .producerId(batch.producerId())
            .producerEpoch(batch.producerEpoch())
            .baseSequence(batch.baseSequence())
            .lastSequence(batch.lastSequence())
            .build();
    }
}
```

##### 3.2 äº‹åŠ¡çŠ¶æ€ç®¡ç†

```java
public class TransactionStateManager {
    
    private final Map<Long, TransactionState> transactionStates = new ConcurrentHashMap<>();
    
    public enum TransactionState {
        OPEN,      // äº‹åŠ¡å¼€å§‹
        COMMITTED, // äº‹åŠ¡æäº¤
        ABORTED    // äº‹åŠ¡ä¸­æ­¢
    }
    
    /**
     * å¤„ç†äº‹åŠ¡æ§åˆ¶æ‰¹æ¬¡
     */
    public void handleTransactionControl(
        TransactionInfo info,
        TransactionControlType type) {
        
        switch (type) {
            case BEGIN:
                transactionStates.put(info.producerId(), TransactionState.OPEN);
                break;
            case COMMIT:
                transactionStates.put(info.producerId(), TransactionState.COMMITTED);
                break;
            case ABORT:
                transactionStates.put(info.producerId(), TransactionState.ABORTED);
                break;
        }
    }
    
    /**
     * æ£€æŸ¥äº‹åŠ¡æ˜¯å¦å·²æäº¤
     */
    public boolean isCommitted(long producerId) {
        return transactionStates.getOrDefault(
            producerId, TransactionState.ABORTED) == TransactionState.COMMITTED;
    }
}
```

##### 3.3 äº‹åŠ¡æ•°æ®å†™å…¥

```java
// åœ¨IcebergWriterä¸­å¤„ç†äº‹åŠ¡
public class IcebergWriter {
    
    private final TransactionStateManager transactionManager;
    
    public void writeBatch(RecordBatch batch, List<GenericRecord> records) {
        // 1. æ£€æŸ¥æ˜¯å¦ä¸ºäº‹åŠ¡æ‰¹æ¬¡
        if (batch.isTransactional()) {
            long producerId = batch.producerId();
            
            // 2. æ£€æŸ¥äº‹åŠ¡çŠ¶æ€
            if (!transactionManager.isCommitted(producerId)) {
                // 3. å»¶è¿Ÿå†™å…¥ï¼Œç­‰å¾…äº‹åŠ¡æäº¤
                pendingTransactions.put(producerId, new PendingBatch(batch, records));
                return;
            }
        }
        
        // 4. å†™å…¥å·²æäº¤çš„æ•°æ®
        writer.writeBatch(records);
    }
    
    /**
     * å¤„ç†äº‹åŠ¡æäº¤
     */
    public void commitTransaction(long producerId) {
        List<PendingBatch> pendingBatches = 
            pendingTransactions.remove(producerId);
        
        if (pendingBatches != null) {
            // å†™å…¥æ‰€æœ‰å¾…å¤„ç†çš„æ‰¹æ¬¡
            for (PendingBatch batch : pendingBatches) {
                writer.writeBatch(batch.records);
            }
        }
    }
}
```

##### 3.4 é…ç½®é¡¹

```properties
# äº‹åŠ¡æ”¯æŒé…ç½®
rsm.config.iceberg.transaction.enabled=true
rsm.config.iceberg.transaction.timeout.ms=300000
rsm.config.iceberg.transaction.pending.batch.max.size=10000
```

##### 3.5 å®ç°æ­¥éª¤

1. **Phase 1: äº‹åŠ¡è¯†åˆ«** (1å‘¨)
   - å®ç°äº‹åŠ¡æ‰¹æ¬¡è¯†åˆ«
   - æå–äº‹åŠ¡ä¿¡æ¯
   - å•å…ƒæµ‹è¯•

2. **Phase 2: äº‹åŠ¡çŠ¶æ€ç®¡ç†** (2å‘¨)
   - å®ç°äº‹åŠ¡çŠ¶æ€è·Ÿè¸ª
   - å¤„ç†äº‹åŠ¡æäº¤/ä¸­æ­¢
   - é›†æˆæµ‹è¯•

3. **Phase 3: äº‹åŠ¡æ•°æ®å†™å…¥** (2å‘¨)
   - å®ç°å»¶è¿Ÿå†™å…¥æœºåˆ¶
   - å¤„ç†äº‹åŠ¡è¶…æ—¶
   - ç«¯åˆ°ç«¯æµ‹è¯•

**é¢„è®¡å·¥ä½œé‡ï¼š** 5å‘¨

---

### 4. ç¼“å­˜æ”¯æŒ

#### éœ€æ±‚æè¿°
å½“å‰Icebergæ¨¡å¼æ²¡æœ‰ç¼“å­˜æœºåˆ¶ï¼Œæ¯æ¬¡è¯»å–éƒ½éœ€è¦ä»å¯¹è±¡å­˜å‚¨è·å–æ•°æ®ï¼Œå½±å“æ€§èƒ½ã€‚

#### å®ç°æ–¹æ¡ˆ

##### 4.1 Parquetæ–‡ä»¶ç¼“å­˜

```java
public class IcebergParquetCache {
    
    private final AsyncCache<String, Path> parquetFileCache;
    
    /**
     * è·å–Parquetæ–‡ä»¶ï¼ˆä»ç¼“å­˜æˆ–å­˜å‚¨ï¼‰
     */
    public Path getParquetFile(String filePath) {
        return parquetFileCache.get(filePath, key -> {
            // ä»å¯¹è±¡å­˜å‚¨ä¸‹è½½
            return downloadParquetFile(key);
        });
    }
    
    /**
     * é¢„å–Parquetæ–‡ä»¶
     */
    public void prefetchParquetFiles(List<String> filePaths) {
        for (String path : filePaths) {
            parquetFileCache.get(path, this::downloadParquetFile);
        }
    }
}
```

##### 4.2 è¡¨å…ƒæ•°æ®ç¼“å­˜

```java
public class IcebergTableMetadataCache {
    
    private final Cache<TableIdentifier, TableMetadata> tableMetadataCache;
    
    /**
     * è·å–è¡¨å…ƒæ•°æ®ï¼ˆä»ç¼“å­˜æˆ–Catalogï¼‰
     */
    public TableMetadata getTableMetadata(TableIdentifier identifier) {
        return tableMetadataCache.get(identifier, () -> {
            Table table = catalog.loadTable(identifier);
            return table.currentSnapshot().metadata();
        });
    }
}
```

##### 4.3 é…ç½®é¡¹

```properties
# Icebergç¼“å­˜é…ç½®
rsm.config.iceberg.cache.enabled=true
rsm.config.iceberg.cache.parquet.file.enabled=true
rsm.config.iceberg.cache.parquet.file.size=17179869184
rsm.config.iceberg.cache.table.metadata.enabled=true
rsm.config.iceberg.cache.table.metadata.expiration.ms=600000
```

##### 4.4 å®ç°æ­¥éª¤

1. **Phase 1: Parquetæ–‡ä»¶ç¼“å­˜** (2å‘¨)
   - å®ç°æ–‡ä»¶ç¼“å­˜
   - é›†æˆåˆ°è¯»å–æµç¨‹
   - æ€§èƒ½æµ‹è¯•

2. **Phase 2: å…ƒæ•°æ®ç¼“å­˜** (1å‘¨)
   - å®ç°è¡¨å…ƒæ•°æ®ç¼“å­˜
   - ç¼“å­˜å¤±æ•ˆç­–ç•¥
   - å•å…ƒæµ‹è¯•

**é¢„è®¡å·¥ä½œé‡ï¼š** 3å‘¨

---

## ğŸŸ¡ ä¸­ä¼˜å…ˆçº§éœ€æ±‚ï¼ˆP1ï¼‰

### 5. è¡¨å‹ç¼©å’Œå¿«ç…§ç®¡ç†

#### éœ€æ±‚æè¿°
æ”¯æŒIcebergè¡¨çš„å‹ç¼©ï¼ˆCompactionï¼‰å’Œå¿«ç…§è¿‡æœŸï¼ˆSnapshot Expirationï¼‰æ“ä½œã€‚

#### å®ç°æ–¹æ¡ˆ

##### 5.1 å‹ç¼©ä»»åŠ¡

```java
public class IcebergCompactionManager {
    
    /**
     * æ‰§è¡Œè¡¨å‹ç¼©
     */
    public void compactTable(TableIdentifier identifier) {
        Table table = catalog.loadTable(identifier);
        
        // 1. é€‰æ‹©éœ€è¦å‹ç¼©çš„æ–‡ä»¶
        List<DataFile> filesToCompact = selectFilesToCompact(table);
        
        // 2. æ‰§è¡Œå‹ç¼©
        RewriteFiles rewriteFiles = table.newRewrite();
        rewriteFiles.rewriteFiles(filesToCompact, compactFiles(filesToCompact));
        rewriteFiles.commit();
    }
}
```

##### 5.2 å¿«ç…§è¿‡æœŸ

```java
public class IcebergSnapshotManager {
    
    /**
     * è¿‡æœŸæ—§å¿«ç…§
     */
    public void expireSnapshots(
        TableIdentifier identifier,
        long olderThanMs,
        int retainLast) {
        
        Table table = catalog.loadTable(identifier);
        ExpireSnapshots expireSnapshots = table.expireSnapshots();
        expireSnapshots.expireOlderThan(olderThanMs)
                       .retainLast(retainLast)
                       .commit();
    }
}
```

##### 5.3 é…ç½®é¡¹

```properties
# å‹ç¼©é…ç½®
rsm.config.iceberg.compaction.enabled=true
rsm.config.iceberg.compaction.interval.ms=3600000
rsm.config.iceberg.compaction.target.file.size=134217728

# å¿«ç…§è¿‡æœŸé…ç½®
rsm.config.iceberg.snapshot.expiration.enabled=true
rsm.config.iceberg.snapshot.expiration.older.than.ms=604800000
rsm.config.iceberg.snapshot.expiration.retain.last=10
```

**é¢„è®¡å·¥ä½œé‡ï¼š** 3å‘¨

---

### 6. ParquetåŠ å¯†

#### éœ€æ±‚æè¿°
æ”¯æŒParquetæ–‡ä»¶çš„åˆ—çº§åŠ å¯†ï¼Œå¢å¼ºæ•°æ®å®‰å…¨æ€§ã€‚

#### å®ç°æ–¹æ¡ˆ

```java
public class EncryptedParquetWriter {
    
    /**
     * åˆ›å»ºåŠ å¯†çš„Parquetå†™å…¥å™¨
     */
    public ParquetWriter<GenericRecord> createEncryptedWriter(
        OutputFile outputFile,
        Schema schema,
        EncryptionKeyMetadata keyMetadata) {
        
        ParquetProperties properties = ParquetProperties.builder()
            .withEncryption(keyMetadata)
            .build();
        
        return ParquetWriter.builder(outputFile)
            .withSchema(schema)
            .withProperties(properties)
            .build();
    }
}
```

**é¢„è®¡å·¥ä½œé‡ï¼š** 2å‘¨

---

### 7. ç§»é™¤è¯»å–æ—¶å¯¹Catalogçš„ä¾èµ–

#### éœ€æ±‚æè¿°
å½“å‰è¯»å–æ—¶éœ€è¦è®¿é—®Catalogè·å–è¡¨å…ƒæ•°æ®ï¼Œå¸Œæœ›ç›´æ¥ä»æ¸…å•æ–‡ä»¶è·å–ï¼Œå‡å°‘ä¾èµ–ã€‚

#### å®ç°æ–¹æ¡ˆ

```java
public class CatalogFreeReader {
    
    /**
     * ä»æ¸…å•æ–‡ä»¶è¯»å–è¡¨å…ƒæ•°æ®
     */
    public TableMetadata readMetadataFromManifest(SegmentManifest manifest) {
        // 1. ä»æ¸…å•ä¸­æå–è¡¨å…ƒæ•°æ®å¼•ç”¨
        // 2. ç›´æ¥ä»å¯¹è±¡å­˜å‚¨è¯»å–å…ƒæ•°æ®æ–‡ä»¶
        // 3. è§£æå¹¶è¿”å›
    }
}
```

**é¢„è®¡å·¥ä½œé‡ï¼š** 2å‘¨

---

### 8. GCSå’ŒAzure Blob Storageæ”¯æŒï¼ˆIcebergæ¨¡å¼ï¼‰

#### éœ€æ±‚æè¿°
å½“å‰Icebergæ¨¡å¼ä»…æ”¯æŒS3ï¼Œéœ€è¦æ”¯æŒGCSå’ŒAzure Blob Storageã€‚

#### å®ç°æ–¹æ¡ˆ

å‚è€ƒS3å®ç°ï¼Œä½¿ç”¨Icebergçš„ç›¸åº”FileIOå®ç°ï¼š
- GCS: `org.apache.iceberg.gcp.gcs.GCSFileIO`
- Azure: `org.apache.iceberg.azure.adlsv2.ADLSFileIO`

**é¢„è®¡å·¥ä½œé‡ï¼š** 2å‘¨

---

## ğŸŸ¢ ä½ä¼˜å…ˆçº§éœ€æ±‚ï¼ˆP2ï¼‰

### 9. å…¶ä»–å­˜å‚¨æ ¼å¼ï¼ˆAvroã€ORCï¼‰

**é¢„è®¡å·¥ä½œé‡ï¼š** 4å‘¨

### 10. å…¶ä»–è®°å½•æ ¼å¼ï¼ˆJSONã€Protobufï¼‰

**é¢„è®¡å·¥ä½œé‡ï¼š** 6å‘¨

### 11. å…¶ä»–è¡¨æ ¼å¼ï¼ˆDelta Lakeï¼‰

**é¢„è®¡å·¥ä½œé‡ï¼š** 8å‘¨

### 12. æ€§èƒ½åŸºå‡†æµ‹è¯•

**é¢„è®¡å·¥ä½œé‡ï¼š** 2å‘¨

### 13. æ¨¡å—åŒ–é‡æ„

**é¢„è®¡å·¥ä½œé‡ï¼š** 3å‘¨

---

## ğŸ“Š æ€»ä½“æ—¶é—´ä¼°ç®—

| ä¼˜å…ˆçº§ | åŠŸèƒ½ | é¢„è®¡å·¥ä½œé‡ |
|--------|------|-----------|
| P0 | Schema Evolution | 5å‘¨ |
| P0 | å»é‡æœºåˆ¶ | 5å‘¨ |
| P0 | Kafkaäº‹åŠ¡æ”¯æŒ | 5å‘¨ |
| P0 | ç¼“å­˜æ”¯æŒ | 3å‘¨ |
| P1 | è¡¨å‹ç¼©å’Œå¿«ç…§ç®¡ç† | 3å‘¨ |
| P1 | ParquetåŠ å¯† | 2å‘¨ |
| P1 | ç§»é™¤Catalogä¾èµ– | 2å‘¨ |
| P1 | GCS/Azureæ”¯æŒ | 2å‘¨ |
| P2 | å…¶ä»–åŠŸèƒ½ | 25å‘¨ |

**P0+P1æ€»è®¡ï¼š** 27å‘¨ï¼ˆçº¦6.5ä¸ªæœˆï¼‰  
**å…¨éƒ¨åŠŸèƒ½æ€»è®¡ï¼š** 52å‘¨ï¼ˆçº¦1å¹´ï¼‰

---

## ğŸ¯ æ¨èå®æ–½é¡ºåº

### ç¬¬ä¸€é˜¶æ®µï¼ˆ3ä¸ªæœˆï¼‰
1. Schema Evolution
2. å»é‡æœºåˆ¶
3. ç¼“å­˜æ”¯æŒ

### ç¬¬äºŒé˜¶æ®µï¼ˆ3ä¸ªæœˆï¼‰
4. Kafkaäº‹åŠ¡æ”¯æŒ
5. è¡¨å‹ç¼©å’Œå¿«ç…§ç®¡ç†
6. GCS/Azureæ”¯æŒ

### ç¬¬ä¸‰é˜¶æ®µï¼ˆæŒ‰éœ€ï¼‰
7. å…¶ä»–åŠŸèƒ½æ ¹æ®éœ€æ±‚ä¼˜å…ˆçº§å®æ–½
